galton.lm$coefficients
names(galton.lm)
dim(galton.lm$coefficients)
galton.lm$coefficients[,4]
str(summary(galton.lm))
str(summary(galton.lm))[4]
summary(galton.lm)[4]
summary(galton.lm)[4][2,4]
summary(galton.lm)[4][4,2]
summary(galton.lm)[[4]]
summary(galton.lm)[[4]][2,4]
p.df <- data.frame(pval=rep(NA, 1000), num=rep(NA,1000))
for (i in 1:1000){
xval <- rnorm(10); yval <- rnorm(10)
lm1 <- lm(yval ~ xval)
pval <- summary(lm1)[[4]][2,4]
p.df$pval[i] <- pval
p.df$num[i] <- i
}
View(p.df)
hist(p.df$pval)
p.df <- data.frame(pval=rep(NA, 100000), num=rep(NA,100000))
for (i in 1:100000){
xval <- rnorm(100); yval <- rnorm(100)
lm1 <- lm(yval ~ xval)
pval <- summary(lm1)[[4]][2,4]
p.df$pval[i] <- pval
p.df$num[i] <- i
}
hist(p.df$pval)
source('~/.active-rstudio-document')
extr.pval()
source('~/.active-rstudio-document')
extr.pval()
View(p.df)
p.df <- extr.pval(number = 10000, size=100)
ggplot(data=p.df, aes(x=pval))+geom_histogram()
ggplot(data=p.df, aes(x=pval))+geom_histogram(binwidth=0.1)
ggplot(data=p.df, aes(x=pval))+geom_histogram(binwidth=0.05)
ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "balck", fill = "gray50") +
xlab("p-values")
ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values")
ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values") +
theme(axis.title = element_text(size=30), # size of axis titles
axis.text = element_text(size=20, colour="gray20"))
ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values") +
theme(axis.title = element_text(size=30), # size of axis titles
axis.text = element_text(size=20, colour="gray20")) +
scale_y_continuous(breaks=seq(0, 600, 100))
GGpvals <- ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values") +
theme(axis.title = element_text(size=30), # size of axis titles
axis.text = element_text(size=20, colour="gray20")) +
scale_y_continuous(breaks=seq(0, 600, 100)) +# Ticks from 0-600, every 100
scale_x_continuous(breaks=seq(0, 1, 0.1))  # Ticks from 0-600, every 100
GGpvals
GGpvals <- ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values") +
theme(axis.title = element_text(size=30), # size of axis titles
axis.text = element_text(size=20, colour="gray20"),
axis.text.x = element_text(angle=90)) +
scale_y_continuous(breaks=seq(0, 600, 100)) +# Ticks from 0-600, every 100
scale_x_continuous(breaks=seq(0, 1, 0.1))  # Ticks from 0-600, every 100
GGpvals
GGpvals <- ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values") +
theme(axis.title = element_text(size=30), # size of axis titles
axis.text = element_text(size=20, colour="gray20"),
axis.text.x = element_text(angle=90, vjust=.5)) +
scale_y_continuous(breaks=seq(0, 600, 100)) +# Ticks from 0-600, every 100
scale_x_continuous(breaks=seq(0, 1, 0.1))  # Ticks from 0-600, every 100
GGpvals
GGpvals <- ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values") +
theme(axis.title = element_text(size=30), # size of axis titles
axis.text = element_text(size=20, colour="gray20"),
axis.text.x = element_text(angle=90, vjust=.6)) +
scale_y_continuous(breaks=seq(0, 600, 100)) +# Ticks from 0-600, every 100
scale_x_continuous(breaks=seq(0, 1, 0.1))  # Ticks from 0-600, every 100
GGpvals
GGpvals <- ggplot(data=p.df, aes(x=pval)) +
geom_histogram(binwidth=0.05, colour = "black", fill = "gray50") +
xlab("p-values") +
theme(axis.title = element_text(size=30), # size of axis titles
axis.text = element_text(size=20, colour="gray20"),
axis.text.x = element_text(angle=90, vjust=.4)) +
scale_y_continuous(breaks=seq(0, 600, 100)) +# Ticks from 0-600, every 100
scale_x_continuous(breaks=seq(0, 1, 0.1))  # Ticks from 0-600, every 100
GGpvals
summary(galton.lm)
confint(galton$parent, level=.95)
confint(galton.lm, level=.95)
names(galton.lm)
summary(galton.lm)
summary(galton.lm)$r.squared
?predict
?rstats
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
summary(lm(y~x))
lm1 <- lm(y~x)
names(summary(lm1))
summary(lm1)$terms
summary(lm1)$sigma
library(UsingR); data(mtcars)
y <- mtcars$mpg
x <- mtcars$wt
?mtcars
x <- x - mean(x)
lm2 <- lm(y~x)
summary(lm2)
?confint
confint(lm2)
x <- mtcars$wt
lm2 <- lm(y~x)
confint(lm2)
summary(lm2)
?preduct
?predict
coef(lm2)
coef(lm2)[1]
newdata <- data.frame(wt=3)
predict(lm2, newdata, interval = ("prediction"))
predict(lm2, newdata)
predict(lm2)
predict(lm2, newdata = newdata)
data(faithful)
lm1 <- (eruptions ~ waiting, data=faithful)
lm1 <- (eruptions ~ waiting, data="faithful")
lm1 <- (faithful$eruptions ~ faithful$waiting)
newdata <- data.frame(waiting=80)
predict(lm1, newdata)
lm1 <- lm(faithful$eruptions ~ faithful$waiting)
predict(lm1, newdata)
summary(lm2)
View(newdata)
new.car <- data.frame(wt=3)
predict(lm2, new.car)
lm2 <- lm(mpg~wt, data=mtcars)
predict(lm2, new.car)
predict(lm2, new.car, interval="predict")
predict(lm2, new.car, interval="confidence")
lm2 <- lm(mpg~I(wt/2), data=mtcars)
confint(lm2)
lm2 <- lm(mpg~I(wt*2), data=mtcars)
confint(lm2)
names(lm2)
lm2$residuals
class(lm2$residuals)
sum(lm2$residuals)
lm1 <- lm(mpg~1, data=mtcars)
summary(lm1)
lm2 <- lm(mpg~wt, data=mtcars)
(lm1$residuals)^2/(lm2$residuals)^2
sum(lm1$residuals)^2/sum(lm2$residuals)^2
summary(lm2)
sum((lm1$residuals)^2)/sum((lm2$residuals)^2)
library(UsingR)
data(mtcars)
?mtcars
load("D:/GoogleDrive/Machine.Learning/week2/1.RData")
rm(list=ls())
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
set.seed(32343)
modelFit <- train(type ~.,data=training,
preProcess=c("center","scale"),method="glm")
modelFit
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
install.packages("RANN")
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
library(ISLR); library(caret); data(Wage);
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass,data=training)
head(predict(dummies,newdata=training))
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
library(splines)
bsBasis <- bs(training$age,df=3)
bsBasis
library(splines)
bsBasis <- bs(training$age,df=3)
head(bsBasis)
lm1 <- lm(wage ~ bsBasis,data=training)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
plot(training$age,training$wage,pch=19,cex=0.5, col="grey")
points(training$age,predict(lm1,newdata=training),col="black",pch=19,cex=0.5)
predict(bsBasis,age=testing$age)
head(predict(bsBasis,age=testing$age))
rm(list=ls())
```{r loadPackage,cache=TRUE,fig.height=3.5,fig.width=3.5}
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=
rm(list=ls())
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$type,predict(modelFit,testing))
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$type,predict(modelFit,testing))
library(ElemStatLearn); data(prostate)
str(prostate)
covnames <- names(prostate[-(9:10)])
y <- prostate$lpsa
x <- prostate[,covnames]
form <- as.formula(paste("lpsa~", paste(covnames, collapse="+"), sep=""))
summary(lm(form, data=prostate[prostate$train,]))
set.seed(1)
train.ind <- sample(nrow(prostate), ceiling(nrow(prostate))/2)
y.test <- prostate$lpsa[-train.ind]
x.test <- x[-train.ind,]
y <- prostate$lpsa[train.ind]
x <- x[train.ind,]
p <- length(covnames)
rss <- list()
for (i in 1:p) {
cat(i)
Index <- combn(p,i)
rss[[i]] <- apply(Index, 2, function(is) {
form <- as.formula(paste("y~", paste(covnames[is], collapse="+"), sep=""))
isfit <- lm(form, data=x)
yhat <- predict(isfit)
train.rss <- sum((y - yhat)^2)
yhat <- predict(isfit, newdata=x.test)
test.rss <- sum((y.test - yhat)^2)
c(train.rss, test.rss)
})
}
png("Plots/selection-plots-01.png", height=432, width=432, pointsize=12)
plot(1:p, 1:p, type="n", ylim=range(unlist(rss)), xlim=c(0,p), xlab="number of predictors", ylab="residual sum of squares", main="Prostate cancer data")
for (i in 1:p) {
points(rep(i-0.15, ncol(rss[[i]])), rss[[i]][1, ], col="blue")
points(rep(i+0.15, ncol(rss[[i]])), rss[[i]][2, ], col="red")
}
minrss <- sapply(rss, function(x) min(x[1,]))
lines((1:p)-0.15, minrss, col="blue", lwd=1.7)
minrss <- sapply(rss, function(x) min(x[2,]))
lines((1:p)+0.15, minrss, col="red", lwd=1.7)
legend("topright", c("Train", "Test"), col=c("blue", "red"), pch=1)
dev.off()
small = prostate[1:5,]
lm(lpsa ~ .,data =small)
rm(list=ls())
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
# Create a building data set and validation set
inBuild <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
validation <- Wage[-inBuild,]; buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y=buildData$wage,
p=0.7, list=FALSE)
training <- buildData[inTrain,]; testing <- buildData[-inTrain,]
dim(training)
dim(testing)
dim(validation)
mod1 <- train(wage ~.,method="glm",data=training)
mod2 <- train(wage ~.,method="rf",
data=training,
trControl = trainControl(method="cv"),number=3)
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data=testing)
predDF <- data.frame(pred1,pred2,wage=testing$wage)
combModFit <- train(wage ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
sqrt(sum((pred1-testing$wage)^2))
sqrt(sum((pred2-testing$wage)^2))
sqrt(sum((combPred-testing$wage)^2))
pred1V <- predict(mod1,validation); pred2V <- predict(mod2,validation)
predVDF <- data.frame(pred1=pred1V,pred2=pred2V)
combPredV <- predict(combModFit,predVDF)
sqrt(sum((pred1V-validation$wage)^2))
sqrt(sum((pred2V-validation$wage)^2))
sqrt(sum((combPredV-validation$wage)^2))
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
install.packages("quantmod")
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
View(GOOG)
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
ts1 <- ts(googOpen,frequency=12)
plot(ts1,xlab="Years+1", ylab="GOOG")
splat <- GOOG[,1:4]
mGoog <- to.monthly(splat)
head(GOOG)
mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
ts1 <- ts(googOpen,frequency=12)
plot(ts1,xlab="Years+1", ylab="GOOG")
splat <- GOOG[,1:4]
mGoog <- to.monthly(splat)
googOpen <- Op(mGoog)
ts1 <- ts(googOpen,frequency=12)
plot(ts1,xlab="Years+1", ylab="GOOG")
splat <- GOOG[,1:4]
mGoog <- to.monthly(splat)
googOpen <- Op(mGoog)
View(googOpen)
View(splat)
View(GOOG)
splat <- GOOG[,1:4]
mGoog <- to.monthly(splat)
rm(list=ls())
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
View(GOOG)
splat <- GOOG[,1:4]
mGoog <- to.monthly(splat)
View(mGoog)
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowe.train)
str(vowel.train)
as.factor(vowel.train$y)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.train)
library)caret
library(caret)
set.seed(33833)
fit1 <- train(y~., data=vowel.train, method="gbm")
fit2 <- train(y~. data=vowel.test, method="rf")
fit2 <- train(y~. data=vowel.test, method="rf", prox=T)
fit2 <- train(y~., data=vowel.test, method="rf", prox=T)
set.seed(33833)
fit1 <- train(y~., data=vowel.train, method="gbm", verbose=F)
fit2 <- train(y~., data=vowel.test, method="rf", prox=T)
vowel.test$yPred.boo <- predict(fit1, newdata=vowel.test)
vowel.test$yPred.rf <- predict(fit2, newdata=vowel.test)
misClass <- function(values, prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
1-misClass(vowel.test$y, vowel.test$yPred.boo)
vowel.test$y
as.numeric(vowel.test$y
)
1-misClass(as.numeric(vowel.test$y), as.numeric(vowel.test$yPred.boo))
table(vowel.test$y, vowel.test$yPred.boo)
?diag
tab.boo <- table(vowel.test$y, vowel.test$yPred.boo)
1-sum(diag(tab.boo))/sum(tab.boo)
sum(diag(tab.boo))/sum(tab.boo)
tab.rf <- table(vowel.test$y, vowel.test$yPred.rf)
sum(diag(tab.rf))/sum(tab.rf)
tab.rf
confusionMatrix(vowel.test$y, vowel.test$yPred.boo)
confusionMatrix(vowel.test$y, vowel.test$yPred.rf)
fit2 <- train(y~., data=vowel.train, method="rf", prox=T)
vowel.test$yPred.rf <- predict(fit2, newdata=vowel.test)
confusionMatrix(vowel.test$y, vowel.test$yPred.rf)
agreeInd <- (vowel.test$yPred.boo == vowel.test$yPred.rf)
table(agreeInd)
vowel.agree <- vowel.test[agreeInd,]
confusionMatrix(vowel.test$y, vowel.test$yPred.rf)
confusionMatrix(vowel.agree$y, vowel.agree$yPred.rf)
names(confusionMatrix(vowel.agree$y, vowel.agree$yPred.rf))
confusionMatrix(vowel.agree$y, vowel.agree$yPred.rf)
confusionMatrix(vowel.agree$y, vowel.agree$yPred.rf)$over
confusionMatrix(vowel.agree$y, vowel.agree$yPred.rf)$overall
confusionMatrix(vowel.agree$y, vowel.agree$yPred.rf)$overall[1]
confusionMatrix(vowel.test$y, vowel.test$yPred.boo)$overall[1]
confusionMatrix(vowel.test$y, vowel.test$yPred.rf)$overall[1]
confusionMatrix(vowel.agree$y, vowel.agree$yPred.rf)$overall[1]
rm(list=ls())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
names(adData)
fit1 <- train(diagnosis~., data=training, method="gbm", verbose=F)
fit2 <- train(diagnosis~., data=training, method="rf", prox=T)
fit3 <- train(diagnosis~., data=training, method="lda")
pred1 <- predict(fit1, testing)
pred2 <- predict(fit2, testing)
pred3 <- predict(fit3, testing)
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combFit <- train(diagnosis~., data=predDF, method="gam")
combPred <- predict(combFit, testing)
confusionMatrix(pred1, testing$diagnosis)$overall[1]
confusionMatrix(pred2, testing$diagnosis)$overall[1]
confusionMatrix(pred3, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
pred1 <- predict(fit1, testing)
pred2 <- predict(fit2, testing)
pred3 <- predict(fit3, testing)
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combFit <- train(diagnosis~., data=predDF, method="rf")
View(predDF)
combPred <- predict(combFit, testing)
confusionMatrix(pred1, testing$diagnosis)$overall[1]
confusionMatrix(pred2, testing$diagnosis)$overall[1]
confusionMatrix(pred3, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
install.packages("Rtools")
install.packages("shiny")
library(shiny)
shiny::runApp('D:/GoogleDrive/Developing.Data.Products/week1/my.shiny.app')
shiny::runApp('D:/GoogleDrive/Developing.Data.Products/week1/my.shiny.app')
shiny::runApp('D:/GoogleDrive/Developing.Data.Products/week1/my.shiny.app')
setwd("D:/GoogleDrive/Developing.Data.Products/week2/project/first_deck")
install.packages("ggthemes")
